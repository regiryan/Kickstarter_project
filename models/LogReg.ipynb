{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import timeit\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('main_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>outcome_state</th>\n",
       "      <th>final_usd_pledged</th>\n",
       "      <th>final_backers_count</th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_description</th>\n",
       "      <th>live_state</th>\n",
       "      <th>in_mid_duration_range</th>\n",
       "      <th>usd_goal</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>currency</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>deadline</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>country</th>\n",
       "      <th>main_category</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_from_launch</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>project_link</th>\n",
       "      <th>creator_link</th>\n",
       "      <th>pledged_to_goal_ratio</th>\n",
       "      <th>description_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464921389</td>\n",
       "      <td>successful</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Good Fishermen Know A Lot About Sex</td>\n",
       "      <td>A musical dramedy about family and dealing wit...</td>\n",
       "      <td>live</td>\n",
       "      <td>True</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>08-21-2019</td>\n",
       "      <td>10-11-2019</td>\n",
       "      <td>False</td>\n",
       "      <td>US</td>\n",
       "      <td>Theater</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>https://www.kickstarter.com/projects/213094288...</td>\n",
       "      <td>https://www.kickstarter.com/profile/2130942887</td>\n",
       "      <td>0.315</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id outcome_state  final_usd_pledged  final_backers_count  \\\n",
       "0   464921389    successful             5660.0                   40   \n",
       "\n",
       "                          project_name  \\\n",
       "0  Good Fishermen Know A Lot About Sex   \n",
       "\n",
       "                                 project_description live_state  \\\n",
       "0  A musical dramedy about family and dealing wit...       live   \n",
       "\n",
       "   in_mid_duration_range  usd_goal  usd_pledged currency launched_at  \\\n",
       "0                   True    5000.0       1575.0      USD  08-21-2019   \n",
       "\n",
       "     deadline  staff_pick country main_category  duration  days_from_launch  \\\n",
       "0  10-11-2019       False      US       Theater        50                21   \n",
       "\n",
       "   backers_count                                       project_link  \\\n",
       "0             24  https://www.kickstarter.com/projects/213094288...   \n",
       "\n",
       "                                     creator_link  pledged_to_goal_ratio  \\\n",
       "0  https://www.kickstarter.com/profile/2130942887                  0.315   \n",
       "\n",
       "   description_len  \n",
       "0               58  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = ['usd_goal', 'pledged_to_goal_ratio', 'duration', 'staff_pick',\n",
    "              'country', 'main_category', 'backers_count', 'description_len', 'outcome_state']\n",
    "continuous_cols = ['usd_goal', 'duration', 'backers_count', 'pledged_to_goal_ratio', 'description_len']\n",
    "categorical_cols = ['staff_pick', 'country', 'main_category']\n",
    "\n",
    "drop_cols = list(set(main_df.columns.to_list()) - set(model_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome_state</th>\n",
       "      <th>usd_goal</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>country</th>\n",
       "      <th>main_category</th>\n",
       "      <th>duration</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>pledged_to_goal_ratio</th>\n",
       "      <th>description_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>successful</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>US</td>\n",
       "      <td>Theater</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>0.315</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  outcome_state  usd_goal  staff_pick country main_category  duration  \\\n",
       "0    successful    5000.0       False      US       Theater        50   \n",
       "\n",
       "   backers_count  pledged_to_goal_ratio  description_len  \n",
       "0             24                  0.315               58  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model_df \n",
    "model_df = main_df.drop(drop_cols, axis=1)\n",
    "model_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding binary variables \n",
    "model_df['outcome_state'] = model_df['outcome_state'].map({'successful': 1, 'failed': 0})\n",
    "model_df['staff_pick'] = model_df['staff_pick'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome_state</th>\n",
       "      <th>usd_goal</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>country</th>\n",
       "      <th>main_category</th>\n",
       "      <th>duration</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>pledged_to_goal_ratio</th>\n",
       "      <th>description_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>Theater</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>Crafts</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome_state  usd_goal  staff_pick country main_category  duration  \\\n",
       "0              1    5000.0           0      US       Theater        50   \n",
       "1              0    1000.0           0      US        Crafts        45   \n",
       "2              0   25000.0           0      US  Film & Video        45   \n",
       "\n",
       "   backers_count  pledged_to_goal_ratio  description_len  \n",
       "0             24                0.31500               58  \n",
       "1              2                0.00600              117  \n",
       "2              2                0.00008               78  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dummy categorical variables\n",
    "def dummy_df(df, todummy_list):\n",
    "    for x in todummy_list:\n",
    "        dummies = pd.get_dummies(df[x], prefix=x, dummy_na=False)\n",
    "        df = df.drop(x, 1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model_df = dummy_df(model_df, ['country', 'main_category'])\n",
    "\n",
    "X = dummy_model_df.drop('outcome_state', axis=1)\n",
    "y = dummy_model_df.loc[:, 'outcome_state']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/regi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='saga')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_preds = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.930372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.950178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.946809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.948490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "accuracy   0.930372\n",
       "recall     0.950178\n",
       "precision  0.946809\n",
       "F1         0.948490"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), f1_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.876351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.845196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.967413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.902184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "accuracy   0.876351\n",
       "recall     0.845196\n",
       "precision  0.967413\n",
       "F1         0.902184"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 0.7\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), f1_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score (Test): 0.9468085106382979\n",
      "Recall Score (Test): 0.9501779359430605\n",
      "accuracy Score (Test): 0.9303721488595438\n",
      "F1 Score (Test): 0.9484902309058614\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix metrics\n",
    "print(f\"Precision Score (Test): {precision_score(y_test, logreg_test_preds)}\")\n",
    "print(f\"Recall Score (Test): {recall_score(y_test, logreg_test_preds)}\")\n",
    "print(f\"accuracy Score (Test): {accuracy_score(y_test, logreg_test_preds)}\")\n",
    "print(f\"F1 Score (Test): {f1_score(y_test, logreg_test_preds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
